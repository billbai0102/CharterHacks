{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchsummary import summary\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('hyperparameters.yaml') as f:\n",
    "    hp = yaml.safe_load(f)['hyperparameters']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "base_path = './data/DermMel'\n",
    "\n",
    "train_labels = pd.read_csv('./data/DermMel/train_labels.csv')\n",
    "val_labels = pd.read_csv('./data/DermMel/val_labels.csv')\n",
    "test_labels = pd.read_csv('./data/DermMel/test_labels.csv')\n",
    "\n",
    "train_images = './data/DermMel/train/'\n",
    "val_images = './data/DermMel/valid/'\n",
    "test_images = './data/DermMel/test/'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_labels.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_labels['target'].hist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "malignant_ids = train_labels.loc[train_labels['target'] == 1]['id'].values\n",
    "benign_ids = train_labels.loc[train_labels['target'] == 0]['id'].values\n",
    "\n",
    "print(f'Malignant: {malignant_ids[:15]}')\n",
    "print(f'Normal: {benign_ids[:15]}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "this function scales down an image to 224 x 224 so that all images are uniform\n",
    "in size, making it easy to feed to the model.\n",
    "\n",
    ":param img: image used to scale down\n",
    "'''\n",
    "def scale_down(img):\n",
    "    img = img.resize((int(img.size[0]/scale_factor), int(round(img.size[1]/scale_factor))))\n",
    "    img = img.crop((37, 0, img.size[0] - 37, 224))\n",
    "    return img"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15., 15.)\n",
    "\n",
    "for m_index, m_id in enumerate(malignant_ids[:3]):\n",
    "    path = os.path.join(train_images, m_id + '.jpeg')\n",
    "    img = Image.open(path)\n",
    "    print(img.size)\n",
    "\n",
    "    plt.subplot(3, 3, m_index + 1)\n",
    "    plt.imshow(np.array(img))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for m_index, m_id in enumerate(benign_ids[:3]):\n",
    "    path = os.path.join(train_images, m_id + '.jpg')\n",
    "    img = Image.open(path)\n",
    "\n",
    "    scale_factor = img.size[1] / 224\n",
    "\n",
    "    img = img.resize((int(img.size[0]/scale_factor), int(round(img.size[1]/scale_factor))))\n",
    "    img = img.crop((37, 0, img.size[0] - 37, 224))\n",
    "\n",
    "    print(img.size)\n",
    "    plt.subplot(3, 3, m_index + 1)\n",
    "    plt.imshow(np.array(img))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MelanomaDataset(Dataset):\n",
    "    def __init__(self, transform, type, csv: pd.DataFrame):\n",
    "        path = os.path.join(base_path, type)\n",
    "        filenames = os.listdir(path)\n",
    "        self.full_filenames = [os.path.join(path, file) for file in filenames]\n",
    "        labels_df = csv\n",
    "        labels_df.set_index(['id'])\n",
    "\n",
    "        self.csv = csv\n",
    "        self.labels = labels_df['target']\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.csv) # 10020\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.full_filenames[idx])\n",
    "        if image.size[0] == 600:\n",
    "            image = scale_down(image)\n",
    "        image = self.transform(image)\n",
    "        return image, self.labels[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_ds = MelanomaDataset(transform, 'train', train_labels)\n",
    "val_ds = MelanomaDataset(transform, 'valid', val_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = 231\n",
    "print(train_ds.__getitem__(x)[0].shape)\n",
    "print(train_ds.__getitem__(x)[1])\n",
    "\n",
    "print(val_ds.__getitem__(x)[0].shape)\n",
    "print(val_ds.__getitem__(x)[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Length of training dataset: {len(train_ds)}')\n",
    "print(f'Length of validation dataset: {len(val_ds)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_img(img, labels):\n",
    "    img = img.numpy()\n",
    "    img = img.transpose(1, 2, 0)\n",
    "    plt.imshow(img, interpolation='nearest')\n",
    "    plt.title(f'Malignant: {labels}')\n",
    "\n",
    "rand_i = np.random.randint(0, len(train_ds), 4)\n",
    "imgs = [train_ds[i][0] for i in rand_i]\n",
    "labels = [train_ds[i][1] for i in rand_i]\n",
    "\n",
    "imgs = utils.make_grid(imgs, nrow=4)\n",
    "plt.rcParams['figure.figsize'] = (15.0, 5)\n",
    "show_img(imgs, labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rand_i = np.random.randint(0, len(val_ds), 4)\n",
    "\n",
    "imgs = utils.make_grid([val_ds[i][0] for i in rand_i], nrow=4)\n",
    "labels = [val_ds[i][1] for i in rand_i]\n",
    "show_img(imgs, labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=.5)\n",
    "    , transforms.RandomVerticalFlip(p=.5)\n",
    "    , transforms.RandomRotation(45)\n",
    "    , transforms.RandomResizedCrop(96, (0.8, 1.0), ratio=(1., 1.))\n",
    "    , transforms.ToTensor()\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = hp['batch_size']\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for x, _ in train_dl:\n",
    "    x = x.shape\n",
    "    print(f'Batch size: {x[0]}, Channels: {x[1]}, Width: {x[2]}, Height: {x[3]}')\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for x, _ in val_dl:\n",
    "    x = x.shape\n",
    "    print(f'Batch size: {x[0]}, Channels: {x[1]}, Width: {x[2]}, Height: {x[3]}')\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "used to calculate convolution layer size (in order to flatter)\n",
    "\n",
    ":param h: input height\n",
    ":param w: input width\n",
    ":param conv: Conv2d object\n",
    ":param pool: pooling size\n",
    "'''\n",
    "def get_conv_size(h, w, conv: nn.Conv2d, pool=1):\n",
    "    size = conv.kernel_size\n",
    "    stride = conv.stride\n",
    "    padding = conv.padding\n",
    "    dilation = conv.dilation\n",
    "\n",
    "    h = np.floor((h + 2 * padding[0] - dilation[0] * (size[0] - 1) - 1) / stride[0] + 1) / pool\n",
    "    w = np.floor((w + 2 * padding[1] - dilation[1] * (size[1] - 1) - 1) / stride[1] + 1) / pool\n",
    "\n",
    "    return int(h), int(w)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        input_channels, input_height, input_width = hp['input_shape']\n",
    "        output_classes = hp['output_classes']\n",
    "\n",
    "        out_1, kernel_1, stride_1, padding_1 = hp['conv1']\n",
    "        out_2, kernel_2, stride_2, padding_2 = hp['conv2']\n",
    "        out_3, kernel_3, stride_3, padding_3 = hp['conv3']\n",
    "        out_4, kernel_4, stride_4, padding_4 = hp['conv4']\n",
    "        out_5, kernel_5, stride_5, padding_5 = hp['conv5']\n",
    "\n",
    "        linear_1 = hp['linear_1']\n",
    "        linear_2 = hp['linear_2']\n",
    "        linear_3 = hp['linear_3']\n",
    "        dropout = hp['dropout']\n",
    "\n",
    "        self.conv_1 = nn.Conv2d(input_channels, out_1, kernel_size=kernel_1, stride=stride_1, padding=padding_1)\n",
    "        self.conv_2 = nn.Conv2d(out_1, out_2, kernel_size=kernel_2, stride=stride_2, padding=padding_2)\n",
    "        self.conv_3 = nn.Conv2d(out_2, out_3, kernel_size=kernel_3, stride=stride_3, padding=padding_3)\n",
    "        self.conv_4 = nn.Conv2d(out_3, out_4, kernel_size=kernel_4, stride=stride_4, padding=padding_4)\n",
    "        self.conv_5 = nn.Conv2d(out_4, out_5, kernel_size=kernel_5, stride=stride_5, padding=padding_5)\n",
    "\n",
    "        h, w = get_conv_size(input_height, input_width, self.conv_1)\n",
    "        h, w = get_conv_size(h, w, self.conv_2, pool=2)\n",
    "        h, w = get_conv_size(h, w, self.conv_3)\n",
    "        h, w = get_conv_size(h, w, self.conv_4, pool=2)\n",
    "        h, w = get_conv_size(h, w, self.conv_5)\n",
    "        self.flat = h * w * out_5\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            # block 1\n",
    "            self.conv_1\n",
    "            , nn.BatchNorm2d(out_1)\n",
    "            , nn.ReLU()\n",
    "\n",
    "            # block 2\n",
    "            , self.conv_2\n",
    "            , nn.BatchNorm2d(out_2)\n",
    "            , nn.ReLU()\n",
    "            , nn.MaxPool2d(2, 2)\n",
    "\n",
    "            # block 3\n",
    "            , self.conv_3\n",
    "            , nn.BatchNorm2d(out_3)\n",
    "            , nn.ReLU()\n",
    "\n",
    "            # block 4\n",
    "            , self.conv_4\n",
    "            , nn.BatchNorm2d(out_4)\n",
    "            , nn.ReLU()\n",
    "            , nn.MaxPool2d(2, 2)\n",
    "\n",
    "            # block 5\n",
    "            , self.conv_5\n",
    "            , nn.BatchNorm2d(out_5)\n",
    "            , nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.classfier = nn.Sequential(\n",
    "            # block 1\n",
    "            nn.Linear(self.flat, linear_1)\n",
    "            , nn.BatchNorm1d(linear_1)\n",
    "            , nn.ReLU()\n",
    "\n",
    "            # block 2\n",
    "            , nn.Linear(linear_1, linear_2)\n",
    "            , nn.BatchNorm1d(linear_2)\n",
    "            , nn.ReLU()\n",
    "\n",
    "            # block 3\n",
    "            , nn.Linear(linear_2, linear_3)\n",
    "            , nn.BatchNorm1d(linear_3)\n",
    "            , nn.ReLU()\n",
    "\n",
    "            , nn.Dropout(p=dropout)\n",
    "\n",
    "            # output\n",
    "            , nn.Linear(linear_3, output_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1, self.flat)\n",
    "        x = self.classfier(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "net = Net().cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "summary(net, input_size=(3, 224, 224))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mode, factor, patience = hp['lr_scheduler']\n",
    "\n",
    "loss = nn.NLLLoss(reduction='sum')\n",
    "optimizer = optim.Adam(params=net.parameters(), lr=0.0001)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode=mode, factor=factor, patience=patience, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "predicts number of correct predictions per batch\n",
    "\n",
    ":param output: output tensor of model\n",
    ":param target: correct answers\n",
    "'''\n",
    "def batch_metrics(output: torch.Tensor, target: torch.Tensor):\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    num_correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "    return num_correct"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "calculates overall loss for batch\n",
    "\n",
    ":param loss_func: loss function of model\n",
    ":param output: output tensor of model\n",
    ":param target: correct answers\n",
    ":param optimizer: optimizer function of model\n",
    "'''\n",
    "def batch_loss(loss_func, output: torch.Tensor, target: torch.Tensor, optimizer=None):\n",
    "    loss = loss_func(output, target)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        metrics = batch_metrics(output, target)\n",
    "\n",
    "    if optimizer is not None:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss.item(), metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "calculates overall loss and performance for epoch\n",
    "\n",
    ":param net: the neural network itself\n",
    ":param loss_func: loss function of model\n",
    ":param dataloader: current dataloader being used\n",
    ":param sanity_check: option for data sanity check\n",
    ":param optimizer: optimizer function of model\n",
    "'''\n",
    "def epoch_loss(net:Net, loss_func, dataloader:DataLoader, sanity_check=False, optimizer=None):\n",
    "    running_loss = 0.\n",
    "    running_metric = 0.\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    # loop over batch\n",
    "    for X_b, y_b in dataloader:\n",
    "        X_b = X_b.cuda()\n",
    "        y_b = y_b.cuda()\n",
    "\n",
    "        # get predictions\n",
    "        out = net(X_b)\n",
    "\n",
    "        # get batch loss and metrics\n",
    "        loss_b, metrics_b = batch_loss(loss_func, out, y_b, optimizer)\n",
    "\n",
    "        # update running loss and accuracy\n",
    "        running_loss += loss_b\n",
    "        if metrics_b is not None:\n",
    "            running_metric += metrics_b\n",
    "\n",
    "        if sanity_check:\n",
    "            break\n",
    "\n",
    "        # calculate overall loss and metric\n",
    "        loss, metric = running_loss / float(size), running_metric / float(size)\n",
    "\n",
    "        return loss, metric"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(model: Net, params):\n",
    "    # load train / val parameters\n",
    "    epochs = params['epochs']\n",
    "    loss = params['loss']\n",
    "    optimizer = params['optimizer']\n",
    "    train_dl = params['train_dl']\n",
    "    val_dl = params['val_dl']\n",
    "    scheduler = params['scheduler']\n",
    "    sanity_check = params['sanity_check']\n",
    "    weights_save = params['weights_save']\n",
    "\n",
    "    # create history object for plotting model performance\n",
    "    history = {\n",
    "        'loss':{\n",
    "            'train': [],\n",
    "            'val': []\n",
    "        },\n",
    "        'metric':{\n",
    "            'train': [],\n",
    "            'val': []\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # save best model weights\n",
    "    best_weights = copy.deepcopy(model.state_dict())\n",
    "    best_loss = float('inf') # set baseline best loss\n",
    "\n",
    "    # train and val loop\n",
    "    for epoch in range(epochs):\n",
    "        lr = optimizer.param_groups[0]['lr']\n",
    "        print(f'Epoch: {epoch + 1}/{epochs} \\t Learning Rate: {lr}')\n",
    "\n",
    "        model.train()\n",
    "        loss_t, metric_t = epoch_loss(model, loss, train_dl, sanity_check, optimizer)\n",
    "\n",
    "        history['loss']['train'].append(loss_t)\n",
    "        history['metric']['train'].append(metric_t)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            loss_v, metric_v = epoch_loss(model, loss, val_dl, sanity_check, optimizer)\n",
    "\n",
    "        history['loss']['val'].append(loss_v)\n",
    "        history['metric']['val'].append(metric_v)\n",
    "\n",
    "        if loss_v < best_loss:\n",
    "            best_loss = loss_v\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "            torch.save(model.state_dict(), weights_save)\n",
    "            print(f'-- Saving optimal weights - Loss: {best_loss:.2f}... --')\n",
    "\n",
    "        scheduler.step(loss_v)\n",
    "        if lr is not optimizer.param_groups[0]['lr']:\n",
    "            model.load_state_dict(best_weights)\n",
    "            print('-- Loading optimal weights... --')\n",
    "\n",
    "        print(f'Train loss: {loss_t:.2f} \\t Val loss: {loss_v:.2f} \\t Accuracy: {metric_v * 100 :.2f}')\n",
    "        print('-' * 15)\n",
    "\n",
    "    model.load_state_dict(best_weights)\n",
    "\n",
    "    return model, history"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_params = {\n",
    "    'epochs': hp['epochs'],                 # epochs\n",
    "    'loss_func': loss,                      # loss function\n",
    "    'optimizer': optimizer,                 # optimizer\n",
    "    'train_dl': train_dl,                   # train DataLoader\n",
    "    'val_dl': val_dl,                       # val DataLoader\n",
    "    'scheduler': scheduler,                 # learning rate scheduler\n",
    "    'sanity_check': False,                  # sanity check toggle\n",
    "    'weights_save': './models/weights.pt'   # output location of saved model weights\n",
    "}\n",
    "\n",
    "net, history = train(net, train_params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "deeplearning",
   "language": "python",
   "display_name": "DeepLearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}